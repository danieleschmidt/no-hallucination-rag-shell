#!/usr/bin/env python3
"""
Generation 2 Enhancement: Make It Robust
- Comprehensive error handling and validation
- Enhanced logging and monitoring
- Security measures and input sanitization
- Circuit breakers and fault tolerance
"""

import logging
import sys
import os
from pathlib import Path

# Add project to path
sys.path.insert(0, str(Path(__file__).parent / 'no_hallucination_rag'))

def enhance_error_handling():
    """Add advanced error handling patterns."""
    print("üõ°Ô∏è Enhancing Error Handling...")
    
    # Create advanced error handler
    error_handler_code = '''
"""
Advanced error handling and fault tolerance system.
"""

import logging
import time
import threading
from typing import Dict, List, Optional, Callable, Any
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime, timedelta
from collections import defaultdict, deque
import functools


class ErrorCategory(Enum):
    """Error categories for classification."""
    VALIDATION = "validation"
    NETWORK = "network"
    COMPUTATION = "computation"
    RESOURCE = "resource"
    SECURITY = "security"
    EXTERNAL_SERVICE = "external_service"
    CONFIGURATION = "configuration"
    UNKNOWN = "unknown"


class ErrorSeverity(Enum):
    """Error severity levels."""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4


@dataclass
class ErrorEvent:
    """Detailed error event information."""
    timestamp: datetime
    error_type: str
    category: ErrorCategory
    severity: ErrorSeverity
    message: str
    component: str
    operation: str
    context: Dict[str, Any] = field(default_factory=dict)
    stack_trace: Optional[str] = None
    recovery_attempted: bool = False
    recovery_successful: bool = False
    occurrence_count: int = 1


class CircuitBreakerState(Enum):
    """Circuit breaker states."""
    CLOSED = "closed"      # Normal operation
    OPEN = "open"          # Failing, blocking requests
    HALF_OPEN = "half_open"  # Testing if service recovered


@dataclass
class CircuitBreakerConfig:
    """Circuit breaker configuration."""
    failure_threshold: int = 5
    recovery_timeout: int = 60
    expected_exception: type = Exception
    success_threshold: int = 3  # For half-open state


class CircuitBreaker:
    """Circuit breaker for fault tolerance."""
    
    def __init__(self, name: str, config: CircuitBreakerConfig):
        self.name = name
        self.config = config
        self.state = CircuitBreakerState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time: Optional[datetime] = None
        self.logger = logging.getLogger(f"{__name__}.{name}")
        self._lock = threading.Lock()
    
    def __call__(self, func):
        """Decorator to apply circuit breaker to a function."""
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            return self._call(func, *args, **kwargs)
        return wrapper
    
    def _call(self, func, *args, **kwargs):
        """Execute function with circuit breaker protection."""
        with self._lock:
            if self.state == CircuitBreakerState.OPEN:
                if self._should_attempt_reset():
                    self.state = CircuitBreakerState.HALF_OPEN
                    self.logger.info(f"Circuit breaker {self.name} entering HALF_OPEN state")
                else:
                    raise CircuitBreakerOpenError(f"Circuit breaker {self.name} is OPEN")
        
        try:
            result = func(*args, **kwargs)
            self._on_success()
            return result
        except self.config.expected_exception as e:
            self._on_failure(e)
            raise
    
    def _should_attempt_reset(self) -> bool:
        """Check if circuit breaker should attempt reset."""
        if not self.last_failure_time:
            return True
        
        return (datetime.utcnow() - self.last_failure_time).total_seconds() >= self.config.recovery_timeout
    
    def _on_success(self):
        """Handle successful call."""
        with self._lock:
            if self.state == CircuitBreakerState.HALF_OPEN:
                self.success_count += 1
                if self.success_count >= self.config.success_threshold:
                    self._reset()
            elif self.state == CircuitBreakerState.CLOSED:
                self.failure_count = max(0, self.failure_count - 1)
    
    def _on_failure(self, exception: Exception):
        """Handle failed call."""
        with self._lock:
            self.failure_count += 1
            self.last_failure_time = datetime.utcnow()
            
            if self.state == CircuitBreakerState.HALF_OPEN:
                self.state = CircuitBreakerState.OPEN
                self.logger.warning(f"Circuit breaker {self.name} opened due to failure in HALF_OPEN state")
            elif self.failure_count >= self.config.failure_threshold:
                self.state = CircuitBreakerState.OPEN
                self.logger.warning(f"Circuit breaker {self.name} opened due to {self.failure_count} failures")
    
    def _reset(self):
        """Reset circuit breaker to closed state."""
        self.state = CircuitBreakerState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.logger.info(f"Circuit breaker {self.name} reset to CLOSED state")
    
    def get_state(self) -> Dict[str, Any]:
        """Get current circuit breaker state."""
        return {
            "name": self.name,
            "state": self.state.value,
            "failure_count": self.failure_count,
            "success_count": self.success_count,
            "last_failure": self.last_failure_time.isoformat() if self.last_failure_time else None
        }


class CircuitBreakerOpenError(Exception):
    """Exception raised when circuit breaker is open."""
    pass


class ErrorPatternDetector:
    """Detect patterns in errors for proactive handling."""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.error_history: deque = deque(maxlen=window_size)
        self.pattern_thresholds = {
            "burst": {"count": 5, "time_window": 60},  # 5 errors in 1 minute
            "sustained": {"count": 20, "time_window": 300},  # 20 errors in 5 minutes
            "cascade": {"different_components": 3, "time_window": 120}  # 3+ components in 2 minutes
        }
        self.logger = logging.getLogger(__name__)
    
    def record_error(self, error_event: ErrorEvent):
        """Record error event and detect patterns."""
        self.error_history.append(error_event)
        patterns = self._detect_patterns()
        
        if patterns:
            self.logger.warning(f"Error patterns detected: {patterns}")
            self._handle_patterns(patterns)
    
    def _detect_patterns(self) -> List[str]:
        """Detect error patterns in recent history."""
        patterns = []
        now = datetime.utcnow()
        
        # Check for burst pattern
        recent_errors = [e for e in self.error_history 
                        if (now - e.timestamp).total_seconds() <= self.pattern_thresholds["burst"]["time_window"]]
        if len(recent_errors) >= self.pattern_thresholds["burst"]["count"]:
            patterns.append("burst")
        
        # Check for sustained pattern
        sustained_errors = [e for e in self.error_history 
                           if (now - e.timestamp).total_seconds() <= self.pattern_thresholds["sustained"]["time_window"]]
        if len(sustained_errors) >= self.pattern_thresholds["sustained"]["count"]:
            patterns.append("sustained")
        
        # Check for cascade pattern
        cascade_errors = [e for e in self.error_history 
                         if (now - e.timestamp).total_seconds() <= self.pattern_thresholds["cascade"]["time_window"]]
        unique_components = set(e.component for e in cascade_errors)
        if len(unique_components) >= self.pattern_thresholds["cascade"]["different_components"]:
            patterns.append("cascade")
        
        return patterns
    
    def _handle_patterns(self, patterns: List[str]):
        """Handle detected error patterns."""
        for pattern in patterns:
            if pattern == "burst":
                self.logger.warning("Burst error pattern detected - temporary rate limiting recommended")
            elif pattern == "sustained":
                self.logger.error("Sustained error pattern detected - system degradation likely")
            elif pattern == "cascade":
                self.logger.critical("Cascade error pattern detected - system-wide failure possible")


class RobustErrorHandler:
    """Enhanced error handling system with patterns, circuit breakers, and recovery."""
    
    def __init__(self):
        self.error_stats: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))
        self.pattern_detector = ErrorPatternDetector()
        self.circuit_breakers: Dict[str, CircuitBreaker] = {}
        self.recovery_strategies: Dict[ErrorCategory, List[Callable]] = defaultdict(list)
        self.logger = logging.getLogger(__name__)
        
        # Setup default recovery strategies
        self._setup_recovery_strategies()
    
    def add_circuit_breaker(self, name: str, config: CircuitBreakerConfig) -> CircuitBreaker:
        """Add circuit breaker for a component."""
        breaker = CircuitBreaker(name, config)
        self.circuit_breakers[name] = breaker
        return breaker
    
    def handle_error(self, exception: Exception, context: Dict[str, Any] = None) -> ErrorEvent:
        """Handle error with comprehensive analysis and recovery."""
        context = context or {}
        
        # Classify error
        category = self._classify_error(exception)
        severity = self._determine_severity(exception, category)
        
        # Create error event
        error_event = ErrorEvent(
            timestamp=datetime.utcnow(),
            error_type=type(exception).__name__,
            category=category,
            severity=severity,
            message=str(exception),
            component=context.get("component", "unknown"),
            operation=context.get("operation", "unknown"),
            context=context,
            stack_trace=self._get_stack_trace()
        )
        
        # Record error for pattern detection
        self.pattern_detector.record_error(error_event)
        
        # Update statistics
        self._update_stats(error_event)
        
        # Attempt recovery
        self._attempt_recovery(error_event)
        
        # Log error
        self._log_error(error_event)
        
        return error_event
    
    def _classify_error(self, exception: Exception) -> ErrorCategory:
        """Classify error into categories."""
        error_type = type(exception).__name__.lower()
        
        if "validation" in error_type or "value" in error_type:
            return ErrorCategory.VALIDATION
        elif "network" in error_type or "connection" in error_type or "timeout" in error_type:
            return ErrorCategory.NETWORK
        elif "memory" in error_type or "resource" in error_type:
            return ErrorCategory.RESOURCE
        elif "permission" in error_type or "auth" in error_type or "security" in error_type:
            return ErrorCategory.SECURITY
        elif "computation" in error_type or "math" in error_type or "overflow" in error_type:
            return ErrorCategory.COMPUTATION
        else:
            return ErrorCategory.UNKNOWN
    
    def _determine_severity(self, exception: Exception, category: ErrorCategory) -> ErrorSeverity:
        """Determine error severity based on type and category."""
        critical_types = ["SystemExit", "MemoryError", "KeyboardInterrupt"]
        high_types = ["ConnectionError", "TimeoutError", "SecurityError"]
        
        error_type = type(exception).__name__
        
        if error_type in critical_types:
            return ErrorSeverity.CRITICAL
        elif error_type in high_types or category == ErrorCategory.SECURITY:
            return ErrorSeverity.HIGH
        elif category in [ErrorCategory.NETWORK, ErrorCategory.RESOURCE]:
            return ErrorSeverity.MEDIUM
        else:
            return ErrorSeverity.LOW
    
    def _get_stack_trace(self) -> str:
        """Get formatted stack trace."""
        import traceback
        return traceback.format_exc()
    
    def _update_stats(self, error_event: ErrorEvent):
        """Update error statistics."""
        self.error_stats[error_event.component][error_event.error_type] += 1
        self.error_stats["global"][error_event.category.value] += 1
        self.error_stats["global"]["total"] += 1
    
    def _attempt_recovery(self, error_event: ErrorEvent):
        """Attempt automatic error recovery."""
        recovery_strategies = self.recovery_strategies.get(error_event.category, [])
        
        error_event.recovery_attempted = len(recovery_strategies) > 0
        
        for strategy in recovery_strategies:
            try:
                success = strategy(error_event)
                if success:
                    error_event.recovery_successful = True
                    self.logger.info(f"Recovery successful for {error_event.error_type}")
                    break
            except Exception as e:
                self.logger.warning(f"Recovery strategy failed: {e}")
    
    def _setup_recovery_strategies(self):
        """Setup default recovery strategies."""
        
        def retry_with_backoff(error_event: ErrorEvent) -> bool:
            """Generic retry with exponential backoff."""
            if "retry_count" not in error_event.context:
                error_event.context["retry_count"] = 0
            
            retry_count = error_event.context["retry_count"]
            if retry_count >= 3:
                return False
            
            wait_time = 2 ** retry_count
            time.sleep(wait_time)
            error_event.context["retry_count"] += 1
            return True
        
        def clear_cache(error_event: ErrorEvent) -> bool:
            """Clear caches on resource errors."""
            # Placeholder for cache clearing logic
            self.logger.info("Clearing caches due to resource error")
            return True
        
        def reset_connection(error_event: ErrorEvent) -> bool:
            """Reset network connections."""
            # Placeholder for connection reset logic
            self.logger.info("Resetting connections due to network error")
            return True
        
        # Register recovery strategies
        self.recovery_strategies[ErrorCategory.NETWORK].append(retry_with_backoff)
        self.recovery_strategies[ErrorCategory.NETWORK].append(reset_connection)
        self.recovery_strategies[ErrorCategory.RESOURCE].append(clear_cache)
        self.recovery_strategies[ErrorCategory.COMPUTATION].append(retry_with_backoff)
    
    def _log_error(self, error_event: ErrorEvent):
        """Log error with appropriate level."""
        log_message = (
            f"[{error_event.category.value.upper()}] {error_event.component}.{error_event.operation}: "
            f"{error_event.error_type} - {error_event.message}"
        )
        
        if error_event.severity == ErrorSeverity.CRITICAL:
            self.logger.critical(log_message)
        elif error_event.severity == ErrorSeverity.HIGH:
            self.logger.error(log_message)
        elif error_event.severity == ErrorSeverity.MEDIUM:
            self.logger.warning(log_message)
        else:
            self.logger.info(log_message)
    
    def get_error_statistics(self) -> Dict[str, Any]:
        """Get comprehensive error statistics."""
        return {
            "total_errors": self.error_stats["global"]["total"],
            "errors_by_category": dict(self.error_stats["global"]),
            "errors_by_component": {k: dict(v) for k, v in self.error_stats.items() if k != "global"},
            "circuit_breaker_states": {name: cb.get_state() for name, cb in self.circuit_breakers.items()},
            "pattern_detector_status": {
                "window_size": self.pattern_detector.window_size,
                "current_errors": len(self.pattern_detector.error_history)
            }
        }
    
    def add_recovery_strategy(self, category: ErrorCategory, strategy: Callable[[ErrorEvent], bool]):
        """Add custom recovery strategy."""
        self.recovery_strategies[category].append(strategy)


# Decorators for common error handling patterns

def with_retry(max_retries: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """Decorator to add retry logic with exponential backoff."""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries:
                        wait_time = delay * (backoff ** attempt)
                        time.sleep(wait_time)
                        logging.warning(f"Retry {attempt + 1}/{max_retries} for {func.__name__} in {wait_time}s")
                    else:
                        logging.error(f"All retries failed for {func.__name__}")
            
            raise last_exception
        return wrapper
    return decorator


def with_timeout(timeout_seconds: int):
    """Decorator to add timeout to function calls."""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError(f"Function {func.__name__} timed out after {timeout_seconds} seconds")
            
            # Set timeout
            old_handler = signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(timeout_seconds)
            
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                signal.alarm(0)  # Cancel alarm
                signal.signal(signal.SIGALRM, old_handler)  # Restore old handler
        return wrapper
    return decorator


def safe_execute(func, *args, default=None, logger=None, **kwargs):
    """Safely execute function with error handling."""
    try:
        return func(*args, **kwargs)
    except Exception as e:
        if logger:
            logger.error(f"Safe execution failed for {func.__name__}: {e}")
        return default
'''
    
    # Write enhanced error handler
    error_handler_path = Path("no_hallucination_rag/core/enhanced_error_handler.py")
    error_handler_path.write_text(error_handler_code)
    print(f"  ‚úÖ Created enhanced error handler: {error_handler_path}")


def enhance_validation():
    """Add comprehensive input validation."""
    print("üîç Enhancing Input Validation...")
    
    validation_code = '''
"""
Comprehensive input validation and sanitization system.
"""

import re
import logging
from typing import Any, Dict, List, Optional, Union, Callable
from dataclasses import dataclass
from enum import Enum
import html
import urllib.parse
from datetime import datetime


class ValidationSeverity(Enum):
    """Validation error severity levels."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class ValidationResult:
    """Result of input validation."""
    is_valid: bool
    errors: List[str]
    warnings: List[str]
    sanitized_input: Any = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []
        if self.warnings is None:
            self.warnings = []
        if self.metadata is None:
            self.metadata = {}


class InputSanitizer:
    """Advanced input sanitization system."""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # Dangerous patterns to detect/remove
        self.sql_injection_patterns = [
            r"(\\');|(\\'\\);",
            r"(select|insert|update|delete|drop|create|alter)\\s+",
            r"union\\s+select",
            r"or\\s+1=1",
            r"--\\s*$",
            r"/\\*.*\\*/"
        ]
        
        self.xss_patterns = [
            r"<script[^>]*>.*?</script>",
            r"javascript:",
            r"on\\w+\\s*=",
            r"<iframe[^>]*>",
            r"<object[^>]*>",
            r"<embed[^>]*>"
        ]
        
        self.command_injection_patterns = [
            r"[;&|`$]",
            r"\\.\\.(/|\\\\)",
            r"(rm|del|format|shutdown)\\s+",
            r">(\\s*[/\\\\]|\\w)",
        ]
    
    def sanitize_string(self, text: str, max_length: Optional[int] = None) -> str:
        """Sanitize string input."""
        if not isinstance(text, str):
            text = str(text)
        
        # Remove null bytes
        text = text.replace('\\x00', '')
        
        # HTML escape
        text = html.escape(text, quote=True)
        
        # URL decode if needed
        if '%' in text:
            try:
                text = urllib.parse.unquote(text)
            except Exception:
                pass  # Keep original if URL decode fails
        
        # Trim whitespace
        text = text.strip()
        
        # Length limit
        if max_length and len(text) > max_length:
            text = text[:max_length]
            self.logger.warning(f"Input truncated to {max_length} characters")
        
        return text
    
    def detect_sql_injection(self, text: str) -> bool:
        """Detect potential SQL injection attempts."""
        text_lower = text.lower()
        
        for pattern in self.sql_injection_patterns:
            if re.search(pattern, text_lower, re.IGNORECASE | re.MULTILINE):
                self.logger.warning(f"Potential SQL injection detected: pattern {pattern}")
                return True
        
        return False
    
    def detect_xss(self, text: str) -> bool:
        """Detect potential XSS attempts."""
        text_lower = text.lower()
        
        for pattern in self.xss_patterns:
            if re.search(pattern, text_lower, re.IGNORECASE | re.MULTILINE):
                self.logger.warning(f"Potential XSS detected: pattern {pattern}")
                return True
        
        return False
    
    def detect_command_injection(self, text: str) -> bool:
        """Detect potential command injection attempts."""
        for pattern in self.command_injection_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                self.logger.warning(f"Potential command injection detected: pattern {pattern}")
                return True
        
        return False
    
    def is_suspicious(self, text: str) -> bool:
        """Check if input contains suspicious patterns."""
        return (self.detect_sql_injection(text) or 
                self.detect_xss(text) or 
                self.detect_command_injection(text))


class ValidationRules:
    """Collection of validation rules."""
    
    @staticmethod
    def required(value: Any) -> ValidationResult:
        """Validate required field."""
        if value is None or (isinstance(value, str) and not value.strip()):
            return ValidationResult(False, ["Field is required"])
        return ValidationResult(True, [])
    
    @staticmethod
    def string_length(value: str, min_length: int = 0, max_length: int = None) -> ValidationResult:
        """Validate string length."""
        if not isinstance(value, str):
            return ValidationResult(False, ["Value must be a string"])
        
        errors = []
        if len(value) < min_length:
            errors.append(f"String too short (minimum {min_length} characters)")
        
        if max_length and len(value) > max_length:
            errors.append(f"String too long (maximum {max_length} characters)")
        
        return ValidationResult(len(errors) == 0, errors)
    
    @staticmethod
    def email_format(email: str) -> ValidationResult:
        """Validate email format."""
        if not isinstance(email, str):
            return ValidationResult(False, ["Email must be a string"])
        
        email_pattern = r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$"
        if not re.match(email_pattern, email):
            return ValidationResult(False, ["Invalid email format"])
        
        return ValidationResult(True, [])
    
    @staticmethod
    def numeric_range(value: Union[int, float], min_value: Union[int, float] = None, 
                     max_value: Union[int, float] = None) -> ValidationResult:
        """Validate numeric range."""
        if not isinstance(value, (int, float)):
            return ValidationResult(False, ["Value must be numeric"])
        
        errors = []
        if min_value is not None and value < min_value:
            errors.append(f"Value too small (minimum {min_value})")
        
        if max_value is not None and value > max_value:
            errors.append(f"Value too large (maximum {max_value})")
        
        return ValidationResult(len(errors) == 0, errors)
    
    @staticmethod
    def regex_pattern(value: str, pattern: str, pattern_name: str = "pattern") -> ValidationResult:
        """Validate against regex pattern."""
        if not isinstance(value, str):
            return ValidationResult(False, ["Value must be a string"])
        
        if not re.match(pattern, value):
            return ValidationResult(False, [f"Value does not match {pattern_name} pattern"])
        
        return ValidationResult(True, [])
    
    @staticmethod
    def allowed_values(value: Any, allowed: List[Any]) -> ValidationResult:
        """Validate value is in allowed list."""
        if value not in allowed:
            return ValidationResult(False, [f"Value must be one of: {allowed}"])
        
        return ValidationResult(True, [])


class AdvancedValidator:
    """Advanced input validation system."""
    
    def __init__(self):
        self.sanitizer = InputSanitizer()
        self.logger = logging.getLogger(__name__)
        self.validation_cache = {}
    
    def validate_query(self, query: str) -> ValidationResult:
        """Validate user query input."""
        errors = []
        warnings = []
        
        # Basic checks
        if not query or not query.strip():
            return ValidationResult(False, ["Query cannot be empty"])
        
        # Length validation
        if len(query) > 10000:  # 10K character limit
            errors.append("Query too long (maximum 10,000 characters)")
        
        if len(query.split()) > 1000:  # 1K word limit
            errors.append("Query has too many words (maximum 1,000)")
        
        # Security validation
        if self.sanitizer.is_suspicious(query):
            errors.append("Query contains potentially malicious content")
        
        # Content quality checks
        if len(query.strip()) < 3:
            warnings.append("Very short query may not produce good results")
        
        # Check for excessive repetition
        words = query.lower().split()
        if len(set(words)) < len(words) * 0.3:  # Less than 30% unique words
            warnings.append("Query contains excessive word repetition")
        
        # Sanitize query
        sanitized = self.sanitizer.sanitize_string(query, max_length=10000)
        
        return ValidationResult(
            is_valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            sanitized_input=sanitized,
            metadata={
                "original_length": len(query),
                "word_count": len(words),
                "unique_words": len(set(words))
            }
        )
    
    def validate_config(self, config: Dict[str, Any]) -> ValidationResult:
        """Validate configuration parameters."""
        errors = []
        warnings = []
        
        required_fields = ["factuality_threshold"]
        for field in required_fields:
            if field not in config:
                errors.append(f"Required configuration field missing: {field}")
        
        # Validate specific config values
        if "factuality_threshold" in config:
            threshold = config["factuality_threshold"]
            if not isinstance(threshold, (int, float)) or not (0 <= threshold <= 1):
                errors.append("factuality_threshold must be a number between 0 and 1")
        
        if "max_sources" in config:
            max_sources = config["max_sources"]
            if not isinstance(max_sources, int) or max_sources < 1:
                errors.append("max_sources must be a positive integer")
            elif max_sources > 100:
                warnings.append("max_sources > 100 may impact performance")
        
        if "min_sources" in config:
            min_sources = config["min_sources"]
            if not isinstance(min_sources, int) or min_sources < 1:
                errors.append("min_sources must be a positive integer")
        
        return ValidationResult(
            is_valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            metadata={"validated_fields": list(config.keys())}
        )
    
    def validate_source_data(self, source: Dict[str, Any]) -> ValidationResult:
        """Validate source document data."""
        errors = []
        warnings = []
        
        required_fields = ["content", "title"]
        for field in required_fields:
            if field not in source or not source[field]:
                errors.append(f"Source missing required field: {field}")
        
        # Validate content
        if "content" in source:
            content = source["content"]
            if len(content) < 10:
                warnings.append("Source content very short (< 10 characters)")
            elif len(content) > 1000000:  # 1MB limit
                errors.append("Source content too large (> 1MB)")
            
            if self.sanitizer.is_suspicious(content):
                errors.append("Source content contains suspicious patterns")
        
        # Validate URL if present
        if "url" in source and source["url"]:
            url = source["url"]
            url_pattern = r"^https?://[\\w\\.-]+\\.[a-zA-Z]{2,}(/.*)?$"
            if not re.match(url_pattern, url):
                warnings.append("URL format appears invalid")
        
        # Validate authority score
        if "authority_score" in source:
            score = source["authority_score"]
            if not isinstance(score, (int, float)) or not (0 <= score <= 1):
                errors.append("authority_score must be between 0 and 1")
        
        return ValidationResult(
            is_valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            metadata={
                "content_length": len(source.get("content", "")),
                "has_url": "url" in source and source["url"]
            }
        )
    
    def batch_validate(self, items: List[Any], validator_func: Callable) -> Dict[str, Any]:
        """Validate multiple items and return summary."""
        results = []
        total_errors = 0
        total_warnings = 0
        
        for i, item in enumerate(items):
            try:
                result = validator_func(item)
                results.append({"index": i, "result": result})
                total_errors += len(result.errors)
                total_warnings += len(result.warnings)
            except Exception as e:
                self.logger.error(f"Validation failed for item {i}: {e}")
                results.append({
                    "index": i, 
                    "result": ValidationResult(False, [f"Validation error: {e}"])
                })
                total_errors += 1
        
        valid_count = sum(1 for r in results if r["result"].is_valid)
        
        return {
            "total_items": len(items),
            "valid_items": valid_count,
            "invalid_items": len(items) - valid_count,
            "total_errors": total_errors,
            "total_warnings": total_warnings,
            "results": results,
            "success_rate": valid_count / len(items) if items else 1.0
        }
'''
    
    validation_path = Path("no_hallucination_rag/core/advanced_validation.py")
    validation_path.write_text(validation_code)
    print(f"  ‚úÖ Created advanced validation system: {validation_path}")


def enhance_monitoring():
    """Add comprehensive monitoring and health checks."""
    print("üìä Enhancing Monitoring and Health Checks...")
    
    monitoring_code = '''
"""
Comprehensive monitoring, health checks, and observability system.
"""

import time
import threading
import logging
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, deque
import psutil
import json
import socket


@dataclass
class HealthCheck:
    """Health check definition."""
    name: str
    check_function: Callable[[], bool]
    description: str
    critical: bool = True
    timeout: int = 5
    interval: int = 60


@dataclass
class HealthStatus:
    """Health check status."""
    name: str
    status: str  # healthy, unhealthy, unknown
    last_check: datetime
    response_time: float
    error_message: Optional[str] = None
    details: Dict[str, Any] = field(default_factory=dict)


@dataclass
class MetricPoint:
    """Single metric data point."""
    timestamp: datetime
    value: float
    labels: Dict[str, str] = field(default_factory=dict)


class HealthMonitor:
    """Comprehensive system health monitoring."""
    
    def __init__(self, check_interval: int = 30):
        self.checks: Dict[str, HealthCheck] = {}
        self.statuses: Dict[str, HealthStatus] = {}
        self.check_interval = check_interval
        self.running = False
        self.monitor_thread: Optional[threading.Thread] = None
        self.logger = logging.getLogger(__name__)
        
        # Setup default health checks
        self._setup_default_checks()
    
    def add_health_check(self, check: HealthCheck):
        """Add a health check."""
        self.checks[check.name] = check
        self.logger.info(f"Added health check: {check.name}")
    
    def remove_health_check(self, name: str):
        """Remove a health check."""
        self.checks.pop(name, None)
        self.statuses.pop(name, None)
        self.logger.info(f"Removed health check: {name}")
    
    def start_monitoring(self):
        """Start continuous health monitoring."""
        if self.running:
            return
        
        self.running = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        self.logger.info("Health monitoring started")
    
    def stop_monitoring(self):
        """Stop health monitoring."""
        self.running = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        self.logger.info("Health monitoring stopped")
    
    def run_check(self, check_name: str) -> HealthStatus:
        """Run a specific health check."""
        check = self.checks.get(check_name)
        if not check:
            return HealthStatus(
                name=check_name,
                status="unknown",
                last_check=datetime.utcnow(),
                response_time=0,
                error_message="Check not found"
            )
        
        start_time = time.time()
        try:
            # Run check with timeout
            result = self._run_with_timeout(check.check_function, check.timeout)
            response_time = time.time() - start_time
            
            status = HealthStatus(
                name=check_name,
                status="healthy" if result else "unhealthy",
                last_check=datetime.utcnow(),
                response_time=response_time,
                details={"critical": check.critical}
            )
            
        except Exception as e:
            response_time = time.time() - start_time
            status = HealthStatus(
                name=check_name,
                status="unhealthy",
                last_check=datetime.utcnow(),
                response_time=response_time,
                error_message=str(e),
                details={"critical": check.critical}
            )
        
        self.statuses[check_name] = status
        return status
    
    def run_all_checks(self) -> Dict[str, HealthStatus]:
        """Run all health checks."""
        results = {}
        for check_name in self.checks:
            results[check_name] = self.run_check(check_name)
        return results
    
    def get_overall_health(self) -> Dict[str, Any]:
        """Get overall system health summary."""
        if not self.statuses:
            self.run_all_checks()
        
        healthy_count = sum(1 for s in self.statuses.values() if s.status == "healthy")
        critical_failures = [s for s in self.statuses.values() 
                           if s.status == "unhealthy" and s.details.get("critical", False)]
        
        overall_status = "healthy"
        if critical_failures:
            overall_status = "critical"
        elif healthy_count < len(self.statuses):
            overall_status = "degraded"
        
        return {
            "status": overall_status,
            "timestamp": datetime.utcnow().isoformat(),
            "total_checks": len(self.statuses),
            "healthy_checks": healthy_count,
            "critical_failures": len(critical_failures),
            "details": {name: {
                "status": status.status,
                "last_check": status.last_check.isoformat(),
                "response_time": status.response_time,
                "error": status.error_message
            } for name, status in self.statuses.items()}
        }
    
    def _monitor_loop(self):
        """Main monitoring loop."""
        while self.running:
            try:
                self.run_all_checks()
                
                # Log critical failures
                critical_failures = [s for s in self.statuses.values() 
                                   if s.status == "unhealthy" and s.details.get("critical", False)]
                
                for failure in critical_failures:
                    self.logger.critical(f"Critical health check failed: {failure.name} - {failure.error_message}")
                
                time.sleep(self.check_interval)
                
            except Exception as e:
                self.logger.error(f"Health monitoring error: {e}")
                time.sleep(min(self.check_interval, 30))  # Back off on errors
    
    def _run_with_timeout(self, func: Callable, timeout: int):
        """Run function with timeout."""
        import signal
        
        def timeout_handler(signum, frame):
            raise TimeoutError(f"Health check timed out after {timeout} seconds")
        
        old_handler = signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(timeout)
        
        try:
            return func()
        finally:
            signal.alarm(0)
            signal.signal(signal.SIGALRM, old_handler)
    
    def _setup_default_checks(self):
        """Setup default system health checks."""
        
        def check_memory():
            """Check memory usage."""
            memory = psutil.virtual_memory()
            return memory.percent < 90  # Less than 90% memory usage
        
        def check_disk():
            """Check disk usage."""
            disk = psutil.disk_usage('/')
            return disk.percent < 95  # Less than 95% disk usage
        
        def check_cpu():
            """Check CPU usage."""
            cpu_percent = psutil.cpu_percent(interval=1)
            return cpu_percent < 95  # Less than 95% CPU usage
        
        def check_file_descriptors():
            """Check file descriptor usage."""
            try:
                process = psutil.Process()
                num_fds = process.num_fds()
                # Check against typical limit (usually 1024 or 4096)
                return num_fds < 800
            except Exception:
                return True  # If can't check, assume healthy
        
        # Add default checks
        self.add_health_check(HealthCheck(
            name="memory",
            check_function=check_memory,
            description="System memory usage",
            critical=True
        ))
        
        self.add_health_check(HealthCheck(
            name="disk",
            check_function=check_disk,
            description="System disk usage",
            critical=True
        ))
        
        self.add_health_check(HealthCheck(
            name="cpu",
            check_function=check_cpu,
            description="System CPU usage",
            critical=False
        ))
        
        self.add_health_check(HealthCheck(
            name="file_descriptors",
            check_function=check_file_descriptors,
            description="Process file descriptors",
            critical=False
        ))


class MetricsCollector:
    """Advanced metrics collection and aggregation."""
    
    def __init__(self, retention_days: int = 7):
        self.metrics: Dict[str, deque] = defaultdict(lambda: deque(maxlen=10000))
        self.retention_days = retention_days
        self.collectors: Dict[str, Callable] = {}
        self.logger = logging.getLogger(__name__)
        self.lock = threading.Lock()
        
        # Start cleanup thread
        self.cleanup_thread = threading.Thread(target=self._cleanup_loop, daemon=True)
        self.cleanup_thread.start()
    
    def record_metric(self, name: str, value: float, labels: Dict[str, str] = None):
        """Record a metric data point."""
        with self.lock:
            point = MetricPoint(
                timestamp=datetime.utcnow(),
                value=value,
                labels=labels or {}
            )
            self.metrics[name].append(point)
    
    def record_counter(self, name: str, increment: float = 1, labels: Dict[str, str] = None):
        """Record counter increment."""
        self.record_metric(f"{name}_total", increment, labels)
    
    def record_histogram(self, name: str, value: float, labels: Dict[str, str] = None):
        """Record histogram value."""
        # Record the value
        self.record_metric(f"{name}", value, labels)
        
        # Calculate and record quantiles periodically
        with self.lock:
            recent_values = [p.value for p in self.metrics[name] 
                           if (datetime.utcnow() - p.timestamp).seconds < 300]  # Last 5 minutes
            
            if len(recent_values) >= 10:
                recent_values.sort()
                n = len(recent_values)
                
                # Record quantiles
                quantiles = [50, 90, 95, 99]
                for q in quantiles:
                    idx = int(n * q / 100)
                    if idx < n:
                        self.record_metric(f"{name}_p{q}", recent_values[idx], labels)
    
    def add_collector(self, name: str, collector_func: Callable[[], Dict[str, float]]):
        """Add custom metric collector."""
        self.collectors[name] = collector_func
    
    def collect_system_metrics(self):
        """Collect system metrics."""
        # Memory metrics
        memory = psutil.virtual_memory()
        self.record_metric("system_memory_usage_percent", memory.percent)
        self.record_metric("system_memory_available_bytes", memory.available)
        
        # CPU metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        self.record_metric("system_cpu_usage_percent", cpu_percent)
        
        # Disk metrics
        disk = psutil.disk_usage('/')
        self.record_metric("system_disk_usage_percent", disk.percent)
        self.record_metric("system_disk_free_bytes", disk.free)
        
        # Network metrics
        try:
            network = psutil.net_io_counters()
            self.record_metric("system_network_bytes_sent", network.bytes_sent)
            self.record_metric("system_network_bytes_recv", network.bytes_recv)
        except Exception as e:
            self.logger.warning(f"Failed to collect network metrics: {e}")
    
    def get_metric_summary(self, name: str, duration_minutes: int = 60) -> Dict[str, Any]:
        """Get metric summary for specified duration."""
        with self.lock:
            if name not in self.metrics:
                return {"error": "Metric not found"}
            
            cutoff_time = datetime.utcnow() - timedelta(minutes=duration_minutes)
            recent_points = [p for p in self.metrics[name] if p.timestamp > cutoff_time]
            
            if not recent_points:
                return {"error": "No recent data"}
            
            values = [p.value for p in recent_points]
            
            return {
                "count": len(values),
                "min": min(values),
                "max": max(values),
                "avg": sum(values) / len(values),
                "latest": values[-1] if values else None,
                "timestamp_range": {
                    "start": recent_points[0].timestamp.isoformat(),
                    "end": recent_points[-1].timestamp.isoformat()
                }
            }
    
    def get_all_metrics(self) -> Dict[str, Any]:
        """Get summary of all metrics."""
        with self.lock:
            return {
                name: self.get_metric_summary(name, 60)
                for name in self.metrics.keys()
            }
    
    def _cleanup_loop(self):
        """Cleanup old metrics periodically."""
        while True:
            try:
                cutoff_time = datetime.utcnow() - timedelta(days=self.retention_days)
                
                with self.lock:
                    for name, points in self.metrics.items():
                        # Remove old points
                        while points and points[0].timestamp < cutoff_time:
                            points.popleft()
                
                time.sleep(3600)  # Run cleanup every hour
                
            except Exception as e:
                self.logger.error(f"Metrics cleanup error: {e}")
                time.sleep(300)  # Wait 5 minutes on error


class SystemMonitor:
    """Integrated system monitoring with health checks and metrics."""
    
    def __init__(self):
        self.health_monitor = HealthMonitor()
        self.metrics_collector = MetricsCollector()
        self.logger = logging.getLogger(__name__)
        self.start_time = datetime.utcnow()
    
    def start(self):
        """Start all monitoring services."""
        self.health_monitor.start_monitoring()
        
        # Setup metrics collection
        self.metrics_collector.add_collector("system", self._collect_system_metrics)
        
        # Start periodic metrics collection
        metrics_thread = threading.Thread(target=self._metrics_collection_loop, daemon=True)
        metrics_thread.start()
        
        self.logger.info("System monitoring started")
    
    def stop(self):
        """Stop all monitoring services."""
        self.health_monitor.stop_monitoring()
        self.logger.info("System monitoring stopped")
    
    def get_status(self) -> Dict[str, Any]:
        """Get comprehensive system status."""
        health = self.health_monitor.get_overall_health()
        uptime = datetime.utcnow() - self.start_time
        
        return {
            "status": health["status"],
            "uptime_seconds": uptime.total_seconds(),
            "health": health,
            "metrics_summary": self.metrics_collector.get_all_metrics(),
            "timestamp": datetime.utcnow().isoformat()
        }
    
    def _collect_system_metrics(self) -> Dict[str, float]:
        """Collect system metrics."""
        try:
            self.metrics_collector.collect_system_metrics()
            return {"status": 1.0}  # Success
        except Exception as e:
            self.logger.error(f"System metrics collection failed: {e}")
            return {"status": 0.0}  # Failure
    
    def _metrics_collection_loop(self):
        """Periodic metrics collection loop."""
        while True:
            try:
                # Collect from all registered collectors
                for name, collector in self.metrics_collector.collectors.items():
                    try:
                        metrics = collector()
                        for metric_name, value in metrics.items():
                            self.metrics_collector.record_metric(f"{name}_{metric_name}", value)
                    except Exception as e:
                        self.logger.error(f"Collector {name} failed: {e}")
                
                time.sleep(30)  # Collect metrics every 30 seconds
                
            except Exception as e:
                self.logger.error(f"Metrics collection loop error: {e}")
                time.sleep(60)  # Back off on errors
'''
    
    monitoring_path = Path("no_hallucination_rag/monitoring/advanced_monitoring.py")
    monitoring_path.write_text(monitoring_code)
    print(f"  ‚úÖ Created advanced monitoring system: {monitoring_path}")


def enhance_security():
    """Add comprehensive security measures.""" 
    print("üîê Enhancing Security...")
    
    security_code = '''
"""
Comprehensive security system with authentication, authorization, and protection.
"""

import hmac
import hashlib
import secrets
import time
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, deque
import ipaddress
import re


@dataclass
class SecurityEvent:
    """Security event for audit logging."""
    timestamp: datetime
    event_type: str
    severity: str  # low, medium, high, critical
    source_ip: Optional[str]
    user_id: Optional[str]
    description: str
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class RateLimitRule:
    """Rate limiting rule configuration."""
    name: str
    max_requests: int
    time_window: int  # seconds
    block_duration: int = 300  # 5 minutes default
    

class RateLimiter:
    """Advanced rate limiting system."""
    
    def __init__(self):
        self.rules: Dict[str, RateLimitRule] = {}
        self.request_history: Dict[str, deque] = defaultdict(lambda: deque())
        self.blocked_clients: Dict[str, datetime] = {}
        self.logger = logging.getLogger(__name__)
    
    def add_rule(self, rule: RateLimitRule):
        """Add rate limiting rule."""
        self.rules[rule.name] = rule
        self.logger.info(f"Added rate limit rule: {rule.name}")
    
    def check_rate_limit(self, client_id: str, rule_name: str) -> Tuple[bool, Dict[str, Any]]:
        """Check if client is within rate limits."""
        if rule_name not in self.rules:
            return True, {"error": "Rule not found"}
        
        rule = self.rules[rule_name]
        now = datetime.utcnow()
        key = f"{rule_name}:{client_id}"
        
        # Check if client is blocked
        if key in self.blocked_clients:
            if now < self.blocked_clients[key]:
                remaining_block = (self.blocked_clients[key] - now).total_seconds()
                return False, {
                    "blocked": True,
                    "remaining_block_time": remaining_block,
                    "reason": "Rate limit exceeded"
                }
            else:
                # Block expired
                del self.blocked_clients[key]
        
        # Clean old requests
        history = self.request_history[key]
        cutoff_time = now - timedelta(seconds=rule.time_window)
        while history and history[0] < cutoff_time:
            history.popleft()
        
        # Check current request count
        if len(history) >= rule.max_requests:
            # Rate limit exceeded - block client
            self.blocked_clients[key] = now + timedelta(seconds=rule.block_duration)
            self.logger.warning(f"Rate limit exceeded for {client_id} on rule {rule_name}")
            
            return False, {
                "blocked": True,
                "reason": "Rate limit exceeded",
                "max_requests": rule.max_requests,
                "time_window": rule.time_window,
                "block_duration": rule.block_duration
            }
        
        # Add current request
        history.append(now)
        
        remaining_requests = rule.max_requests - len(history)
        return True, {
            "allowed": True,
            "remaining_requests": remaining_requests,
            "reset_time": (now + timedelta(seconds=rule.time_window)).isoformat()
        }


class IPWhitelist:
    """IP address whitelist/blacklist management."""
    
    def __init__(self):
        self.whitelist: List[ipaddress.IPv4Network] = []
        self.blacklist: List[ipaddress.IPv4Network] = []
        self.logger = logging.getLogger(__name__)
    
    def add_to_whitelist(self, ip_or_network: str):
        """Add IP or network to whitelist."""
        try:
            network = ipaddress.IPv4Network(ip_or_network, strict=False)
            self.whitelist.append(network)
            self.logger.info(f"Added to whitelist: {ip_or_network}")
        except ValueError as e:
            self.logger.error(f"Invalid IP/network for whitelist: {ip_or_network} - {e}")
    
    def add_to_blacklist(self, ip_or_network: str):
        """Add IP or network to blacklist."""
        try:
            network = ipaddress.IPv4Network(ip_or_network, strict=False)
            self.blacklist.append(network)
            self.logger.info(f"Added to blacklist: {ip_or_network}")
        except ValueError as e:
            self.logger.error(f"Invalid IP/network for blacklist: {ip_or_network} - {e}")
    
    def is_allowed(self, ip_address: str) -> Tuple[bool, str]:
        """Check if IP address is allowed."""
        try:
            ip = ipaddress.IPv4Address(ip_address)
            
            # Check blacklist first
            for network in self.blacklist:
                if ip in network:
                    return False, f"IP {ip_address} is blacklisted"
            
            # If whitelist is empty, allow all (except blacklisted)
            if not self.whitelist:
                return True, "No whitelist configured"
            
            # Check whitelist
            for network in self.whitelist:
                if ip in network:
                    return True, f"IP {ip_address} is whitelisted"
            
            return False, f"IP {ip_address} not in whitelist"
            
        except ValueError as e:
            return False, f"Invalid IP address: {ip_address} - {e}"


class APIKeyManager:
    """API key management and validation."""
    
    def __init__(self):
        self.keys: Dict[str, Dict[str, Any]] = {}
        self.key_usage: Dict[str, List[datetime]] = defaultdict(list)
        self.logger = logging.getLogger(__name__)
    
    def generate_key(self, user_id: str, permissions: List[str] = None, expires_in_days: int = 30) -> str:
        """Generate new API key."""
        api_key = secrets.token_urlsafe(32)
        
        self.keys[api_key] = {
            "user_id": user_id,
            "created_at": datetime.utcnow(),
            "expires_at": datetime.utcnow() + timedelta(days=expires_in_days),
            "permissions": permissions or ["read"],
            "active": True,
            "usage_count": 0
        }
        
        self.logger.info(f"Generated API key for user {user_id}")
        return api_key
    
    def validate_key(self, api_key: str) -> Tuple[bool, Dict[str, Any]]:
        """Validate API key."""
        if api_key not in self.keys:
            return False, {"error": "Invalid API key"}
        
        key_data = self.keys[api_key]
        
        # Check if key is active
        if not key_data["active"]:
            return False, {"error": "API key is disabled"}
        
        # Check expiration
        if datetime.utcnow() > key_data["expires_at"]:
            return False, {"error": "API key has expired"}
        
        # Update usage
        key_data["usage_count"] += 1
        self.key_usage[api_key].append(datetime.utcnow())
        
        return True, {
            "user_id": key_data["user_id"],
            "permissions": key_data["permissions"],
            "usage_count": key_data["usage_count"]
        }
    
    def revoke_key(self, api_key: str):
        """Revoke API key."""
        if api_key in self.keys:
            self.keys[api_key]["active"] = False
            self.logger.info(f"Revoked API key for user {self.keys[api_key]['user_id']}")
    
    def get_key_stats(self, api_key: str) -> Dict[str, Any]:
        """Get API key usage statistics."""
        if api_key not in self.keys:
            return {"error": "API key not found"}
        
        key_data = self.keys[api_key]
        usage_history = self.key_usage[api_key]
        
        # Calculate usage stats
        now = datetime.utcnow()
        last_24h = sum(1 for usage in usage_history if (now - usage).total_seconds() < 86400)
        last_7d = sum(1 for usage in usage_history if (now - usage).total_seconds() < 604800)
        
        return {
            "user_id": key_data["user_id"],
            "created_at": key_data["created_at"].isoformat(),
            "expires_at": key_data["expires_at"].isoformat(),
            "total_usage": key_data["usage_count"],
            "usage_last_24h": last_24h,
            "usage_last_7d": last_7d,
            "active": key_data["active"]
        }


class SecurityAuditor:
    """Security event logging and analysis."""
    
    def __init__(self, max_events: int = 10000):
        self.events: deque = deque(maxlen=max_events)
        self.alert_thresholds = {
            "failed_auth_burst": {"count": 5, "time_window": 300},  # 5 failures in 5 minutes
            "suspicious_queries": {"count": 10, "time_window": 600},  # 10 suspicious queries in 10 minutes
            "rate_limit_violations": {"count": 3, "time_window": 300}  # 3 rate limit violations in 5 minutes
        }
        self.logger = logging.getLogger(__name__)
    
    def log_event(self, event: SecurityEvent):
        """Log security event."""
        self.events.append(event)
        
        # Log to standard logger
        log_level = {
            "low": logging.INFO,
            "medium": logging.WARNING,
            "high": logging.ERROR,
            "critical": logging.CRITICAL
        }.get(event.severity, logging.INFO)
        
        self.logger.log(log_level, f"[SECURITY] {event.event_type}: {event.description}")
        
        # Check for alert conditions
        self._check_alerts(event)
    
    def log_auth_failure(self, source_ip: str, user_id: str = None, reason: str = ""):
        """Log authentication failure."""
        event = SecurityEvent(
            timestamp=datetime.utcnow(),
            event_type="auth_failure",
            severity="medium",
            source_ip=source_ip,
            user_id=user_id,
            description=f"Authentication failed: {reason}",
            metadata={"reason": reason}
        )
        self.log_event(event)
    
    def log_suspicious_query(self, source_ip: str, query: str, user_id: str = None):
        """Log suspicious query."""
        event = SecurityEvent(
            timestamp=datetime.utcnow(),
            event_type="suspicious_query",
            severity="high",
            source_ip=source_ip,
            user_id=user_id,
            description=f"Suspicious query detected: {query[:100]}...",
            metadata={"query_length": len(query)}
        )
        self.log_event(event)
    
    def log_rate_limit_violation(self, source_ip: str, rule_name: str, user_id: str = None):
        """Log rate limit violation."""
        event = SecurityEvent(
            timestamp=datetime.utcnow(),
            event_type="rate_limit_violation",
            severity="medium",
            source_ip=source_ip,
            user_id=user_id,
            description=f"Rate limit violated: {rule_name}",
            metadata={"rule": rule_name}
        )
        self.log_event(event)
    
    def get_security_summary(self, hours: int = 24) -> Dict[str, Any]:
        """Get security events summary."""
        cutoff_time = datetime.utcnow() - timedelta(hours=hours)
        recent_events = [e for e in self.events if e.timestamp > cutoff_time]
        
        # Count by event type
        event_counts = defaultdict(int)
        severity_counts = defaultdict(int)
        source_ips = defaultdict(int)
        
        for event in recent_events:
            event_counts[event.event_type] += 1
            severity_counts[event.severity] += 1
            if event.source_ip:
                source_ips[event.source_ip] += 1
        
        # Top IPs by event count
        top_ips = sorted(source_ips.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            "time_range_hours": hours,
            "total_events": len(recent_events),
            "events_by_type": dict(event_counts),
            "events_by_severity": dict(severity_counts),
            "top_source_ips": top_ips,
            "latest_events": [
                {
                    "timestamp": e.timestamp.isoformat(),
                    "type": e.event_type,
                    "severity": e.severity,
                    "description": e.description
                }
                for e in list(recent_events)[-10:]
            ]
        }
    
    def _check_alerts(self, event: SecurityEvent):
        """Check if event triggers security alerts."""
        now = datetime.utcnow()
        
        # Check for auth failure bursts
        if event.event_type == "auth_failure":
            recent_failures = [e for e in self.events 
                             if e.event_type == "auth_failure" 
                             and e.source_ip == event.source_ip
                             and (now - e.timestamp).total_seconds() < 300]
            
            if len(recent_failures) >= 5:
                self.logger.critical(f"ALERT: Authentication failure burst from {event.source_ip}")
        
        # Check for suspicious query patterns
        elif event.event_type == "suspicious_query":
            recent_suspicious = [e for e in self.events
                               if e.event_type == "suspicious_query"
                               and (now - e.timestamp).total_seconds() < 600]
            
            if len(recent_suspicious) >= 10:
                self.logger.critical("ALERT: High volume of suspicious queries detected")


class ComprehensiveSecurityManager:
    """Integrated security management system."""
    
    def __init__(self):
        self.rate_limiter = RateLimiter()
        self.ip_whitelist = IPWhitelist()
        self.api_key_manager = APIKeyManager()
        self.auditor = SecurityAuditor()
        self.logger = logging.getLogger(__name__)
        
        # Setup default rate limits
        self._setup_default_rules()
    
    def validate_request(self, 
                        client_ip: str = None,
                        api_key: str = None,
                        user_id: str = None,
                        query: str = None) -> Tuple[bool, Dict[str, Any]]:
        """Comprehensive request validation."""
        
        # IP whitelist check
        if client_ip:
            ip_allowed, ip_message = self.ip_whitelist.is_allowed(client_ip)
            if not ip_allowed:
                self.auditor.log_event(SecurityEvent(
                    timestamp=datetime.utcnow(),
                    event_type="ip_blocked",
                    severity="high",
                    source_ip=client_ip,
                    description=ip_message
                ))
                return False, {"error": "IP address not allowed", "details": ip_message}
        
        # API key validation
        if api_key:
            key_valid, key_data = self.api_key_manager.validate_key(api_key)
            if not key_valid:
                if client_ip:
                    self.auditor.log_auth_failure(client_ip, user_id, key_data.get("error", "Invalid key"))
                return False, {"error": "Invalid API key", "details": key_data}
            
            user_id = key_data.get("user_id", user_id)
        
        # Rate limiting
        if client_ip:
            rate_ok, rate_info = self.rate_limiter.check_rate_limit(client_ip, "general")
            if not rate_ok:
                self.auditor.log_rate_limit_violation(client_ip, "general", user_id)
                return False, {"error": "Rate limit exceeded", "details": rate_info}
        
        # Query validation (basic security)
        if query:
            if self._is_suspicious_query(query):
                self.auditor.log_suspicious_query(client_ip or "unknown", query, user_id)
                return False, {"error": "Query contains suspicious content"}
        
        return True, {"user_id": user_id, "permissions": key_data.get("permissions", []) if api_key else []}
    
    def _setup_default_rules(self):
        """Setup default security rules."""
        # General rate limit: 100 requests per minute
        self.rate_limiter.add_rule(RateLimitRule(
            name="general",
            max_requests=100,
            time_window=60,
            block_duration=300
        ))
        
        # Strict rate limit for suspicious IPs: 10 requests per minute
        self.rate_limiter.add_rule(RateLimitRule(
            name="strict",
            max_requests=10,
            time_window=60,
            block_duration=600
        ))
    
    def _is_suspicious_query(self, query: str) -> bool:
        """Basic suspicious query detection."""
        suspicious_patterns = [
            r"<script",
            r"javascript:",
            r"union\s+select",
            r"drop\s+table",
            r"exec\s*\(",
            r"\.\.\/",
            r"cmd\.exe",
            r"/bin/sh"
        ]
        
        query_lower = query.lower()
        for pattern in suspicious_patterns:
            if re.search(pattern, query_lower):
                return True
        
        return False
    
    def get_security_status(self) -> Dict[str, Any]:
        """Get comprehensive security status."""
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "rate_limiter": {
                "rules_count": len(self.rate_limiter.rules),
                "blocked_clients": len(self.rate_limiter.blocked_clients)
            },
            "ip_controls": {
                "whitelist_entries": len(self.ip_whitelist.whitelist),
                "blacklist_entries": len(self.ip_whitelist.blacklist)
            },
            "api_keys": {
                "total_keys": len(self.api_key_manager.keys),
                "active_keys": sum(1 for k in self.api_key_manager.keys.values() if k["active"])
            },
            "security_events": self.auditor.get_security_summary(24)
        }
'''
    
    security_path = Path("no_hallucination_rag/security/advanced_security.py")
    security_path.write_text(security_code)
    print(f"  ‚úÖ Created advanced security system: {security_path}")


def main():
    """Execute Generation 2 enhancements."""
    print("üõ°Ô∏è GENERATION 2: MAKE IT ROBUST")
    print("=" * 50)
    
    try:
        enhance_error_handling()
        enhance_validation()  
        enhance_monitoring()
        enhance_security()
        
        print("\nüéâ GENERATION 2 ENHANCEMENTS COMPLETE!")
        print("‚úÖ Advanced error handling and circuit breakers")
        print("‚úÖ Comprehensive input validation and sanitization")
        print("‚úÖ Enhanced monitoring and health checks")
        print("‚úÖ Enterprise-grade security measures")
        print("\nüöÄ System is now ROBUST and RELIABLE")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Generation 2 enhancement failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)